---
title: "R Notebook"
output: html_notebook
author: Bhoj Rani Soopal 
---

```{r}
library(readxl)
setwd("/Users/divyashie/Desktop/project_timeSeries")
df <- read_excel("ccovid.xlsx")
summary(df, na.rm = TRUE)
```

```{r}
lib <- c("ggthemes", "forecast", "tidyverse", "tseries", "lubridate", "timetk", "tidyquant", "scales", "sweep", "broom", "tibble", "stringr", "highcharter", "knitr")
lapply(lib, require, character.only =TRUE)
theme_set(theme_classic()) 
```

```{r}
head(df)
```

```{r}
df%>%ggplot(aes(dateRep,cases))+geom_line()+
geom_point(alpha = 0.5, color = palette_light()[[1]], shape=20,size=2) +
   labs(title = "Infection cases Forecasting", x = "Time", y = "Number of \n Infections",subtitle = "data from 2019 & 2020") + theme_tq()
```


```{r}
df%>%ggplot(aes(dateRep,deaths))+geom_line()+
geom_point(alpha = 0.5, color = palette_dark()[[1]], shape=20,size=2) +
   labs(title = "Death cases Forecasting", x = "Time", y = "Number of \n Deaths",subtitle = "data from 2019 & 2020") + theme_tq()
```
```{r}
library(keras)
library(tensorflow)
library(ggplot2)
library(stats)
library(readr)
library(dplyr)
library(forecast)
library(Metrics)

```
```{r}
#Transform into stationarity 
diff <- diff(df$dateRep, differences=1)
```

```{r}
#Create Lagged Dataset  
supervised <- as.data.frame(cbind(lag(diff,1),diff))
supervised[is.na(supervised)] <-0 
```


```{r}
#Split into training and test set 
N = nrow(supervised)
n = round(N*0.85, digits=0)
train = supervised[1:n,]
test = supervised[(n+1):N, ]
head(test)
```


```{r}
#Normalization of data 
normalize <- function(train,test,feature_range=c(0,1)){
  std_train = (train-min(train))/(max(train)-min(train))
  std_test = (test-min(train))
  
  scaled_train = std_train * (feature_range[2] - feature_range[1] ) + feature_range[1]
  scaled_test = std_test * (feature_range[2] - feature_range[1]) + feature_range[1]
  
  return (list(scaled_train = as.vector(scaled_train), scaled_test=as.vector(scaled_test), scaler=c(min=min(train), max=max(train))))
}
```

```{r}
#Function to reverse scale data for prediction 

reverse <- function(scaled, scaler, feature_range=c(0,1)) {
  for (i in 1:length(scaled)){
    res = (scaled[i] - feature_range[1])/ (feature_range[2] - feature_range[1])
    raw_values = res * (scaler[2] - scaler[1]) + scaler[1]
    
    inverted_df[i] <- raw_values
  }
  return (inverted_df)
}
```

```{r}
Scaled <- normalize(train, test, c(-1,1))

x_train <- Scaled$scaled_train[,1]
y_train <- Scaled$scaled_train[,2]

x_test <- Scaled$scaled_test[,1]
y_test <- Scaled$scaled_test[,2]

head(x_train)
head(y_train)
```


```{r}
#LSTM requires further model parameterization 
library(keras)
dim(x_train) <- c(length(x_train), 1,1)
dim(x_train)
X_shape2 <- dim(x_train)[2]
X_shape3 <- dim(x_train)[3]
batch_size <- 1
units <- 100


model <- keras_model_sequential()
model %>% 
  layer_lstm(units, batch_input_shape = c(batch_size, X_shape2, X_shape3), stateful = TRUE) %>%
  layer_dense(units = 1)
```

```{r}
model %>% 
  compile(loss = 'mean_squared_error',
          optimizer = optimizer_adam(lr = 0.02, decay = 1e-6),
          metrics = c("accuracy")
          )
```

```{r}
summary(model)
```

```{r}
dim(y_train)
```


```{r}
 nb_epoch = 10
  for(i in 1:nb_epoch ){
    model %>% fit(x_train, y_train, epochs=1, batch_size=batch_size, verbose=1, shuffle=FALSE)
    model %>% reset_states()
  }
  
```

```{r}
library(plotly)
pred <- model %>% predict(x_test, batch_size) %>% .[1,]
plot_ly(df, x = ~dateRep, y = ~deaths, type = "scatter", mode = "markers", color = ~vol) %>%
 add_trace(y = c(rep(NA, 5), pred), x = myts$dateRep, name = "LSTM prediction", mode = "lines")
```

```{r}
plot(y_test, pred)
```

